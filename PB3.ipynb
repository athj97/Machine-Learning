{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_csv(\"spambase.data\", header = None)\n",
    "train, test = train_test_split(f, train_size = 2/3)#Random splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Zscore(x, dataset):#Re-used from last homework(s)\n",
    "    for i in range(dataset.shape[1] - 1):\n",
    "        col = dataset.iloc[:, i].to_numpy()\n",
    "        temp = (col - np.mean(col))/ (np.std(col, ddof = 1))\n",
    "        x = np.append(x, temp.reshape(-1, 1), axis = 1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.348066</td>\n",
       "      <td>-0.164411</td>\n",
       "      <td>-0.559200</td>\n",
       "      <td>-0.048325</td>\n",
       "      <td>-0.456769</td>\n",
       "      <td>-0.351222</td>\n",
       "      <td>-0.288121</td>\n",
       "      <td>-0.253302</td>\n",
       "      <td>-0.338807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071767</td>\n",
       "      <td>-0.102237</td>\n",
       "      <td>-0.151829</td>\n",
       "      <td>-0.494795</td>\n",
       "      <td>-0.144416</td>\n",
       "      <td>1.094799</td>\n",
       "      <td>-0.294335</td>\n",
       "      <td>-0.122611</td>\n",
       "      <td>-0.141426</td>\n",
       "      <td>-0.240009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.348066</td>\n",
       "      <td>1.383830</td>\n",
       "      <td>-0.559200</td>\n",
       "      <td>-0.048325</td>\n",
       "      <td>-0.456769</td>\n",
       "      <td>-0.351222</td>\n",
       "      <td>-0.288121</td>\n",
       "      <td>-0.253302</td>\n",
       "      <td>-0.338807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071767</td>\n",
       "      <td>-0.102237</td>\n",
       "      <td>0.243771</td>\n",
       "      <td>-0.098018</td>\n",
       "      <td>-0.144416</td>\n",
       "      <td>-0.188260</td>\n",
       "      <td>-0.294335</td>\n",
       "      <td>-0.122611</td>\n",
       "      <td>-0.087883</td>\n",
       "      <td>-0.176564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.049347</td>\n",
       "      <td>-0.164411</td>\n",
       "      <td>1.593409</td>\n",
       "      <td>-0.048325</td>\n",
       "      <td>1.087371</td>\n",
       "      <td>3.486176</td>\n",
       "      <td>-0.288121</td>\n",
       "      <td>-0.253302</td>\n",
       "      <td>-0.338807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071767</td>\n",
       "      <td>-0.102237</td>\n",
       "      <td>-0.151829</td>\n",
       "      <td>0.815985</td>\n",
       "      <td>-0.144416</td>\n",
       "      <td>-0.108206</td>\n",
       "      <td>-0.294335</td>\n",
       "      <td>-0.122611</td>\n",
       "      <td>-0.096687</td>\n",
       "      <td>-0.144842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.348066</td>\n",
       "      <td>-0.164411</td>\n",
       "      <td>0.486928</td>\n",
       "      <td>-0.048325</td>\n",
       "      <td>-0.456769</td>\n",
       "      <td>-0.351222</td>\n",
       "      <td>-0.288121</td>\n",
       "      <td>-0.253302</td>\n",
       "      <td>-0.338807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071767</td>\n",
       "      <td>-0.102237</td>\n",
       "      <td>-0.151829</td>\n",
       "      <td>-0.229096</td>\n",
       "      <td>1.184919</td>\n",
       "      <td>-0.311083</td>\n",
       "      <td>-0.294335</td>\n",
       "      <td>-0.122611</td>\n",
       "      <td>-0.090337</td>\n",
       "      <td>-0.162969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.064704</td>\n",
       "      <td>-0.064276</td>\n",
       "      <td>-0.297668</td>\n",
       "      <td>-0.048325</td>\n",
       "      <td>0.336948</td>\n",
       "      <td>0.617094</td>\n",
       "      <td>0.398944</td>\n",
       "      <td>0.057602</td>\n",
       "      <td>3.815415</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071767</td>\n",
       "      <td>-0.102237</td>\n",
       "      <td>-0.151829</td>\n",
       "      <td>-0.434570</td>\n",
       "      <td>-0.144416</td>\n",
       "      <td>1.132084</td>\n",
       "      <td>0.397652</td>\n",
       "      <td>-0.122611</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.806835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3         4         5         6         7   \\\n",
       "0  1.0 -0.348066 -0.164411 -0.559200 -0.048325 -0.456769 -0.351222 -0.288121   \n",
       "1  1.0 -0.348066  1.383830 -0.559200 -0.048325 -0.456769 -0.351222 -0.288121   \n",
       "2  1.0  3.049347 -0.164411  1.593409 -0.048325  1.087371  3.486176 -0.288121   \n",
       "3  1.0 -0.348066 -0.164411  0.486928 -0.048325 -0.456769 -0.351222 -0.288121   \n",
       "4  1.0  0.064704 -0.064276 -0.297668 -0.048325  0.336948  0.617094  0.398944   \n",
       "\n",
       "         8         9   ...        47        48        49        50        51  \\\n",
       "0 -0.253302 -0.338807  ... -0.071767 -0.102237 -0.151829 -0.494795 -0.144416   \n",
       "1 -0.253302 -0.338807  ... -0.071767 -0.102237  0.243771 -0.098018 -0.144416   \n",
       "2 -0.253302 -0.338807  ... -0.071767 -0.102237 -0.151829  0.815985 -0.144416   \n",
       "3 -0.253302 -0.338807  ... -0.071767 -0.102237 -0.151829 -0.229096  1.184919   \n",
       "4  0.057602  3.815415  ... -0.071767 -0.102237 -0.151829 -0.434570 -0.144416   \n",
       "\n",
       "         52        53        54        55        56  \n",
       "0  1.094799 -0.294335 -0.122611 -0.141426 -0.240009  \n",
       "1 -0.188260 -0.294335 -0.122611 -0.087883 -0.176564  \n",
       "2 -0.108206 -0.294335 -0.122611 -0.096687 -0.144842  \n",
       "3 -0.311083 -0.294335 -0.122611 -0.090337 -0.162969  \n",
       "4  1.132084  0.397652 -0.122611  0.000982  0.806835  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_train = np.ones(train.shape[0]).reshape(-1, 1)\n",
    "bias_test = np.ones(test.shape[0]).reshape(-1, 1)\n",
    "zscored_train = pd.DataFrame(Zscore(bias_train, train.iloc[:, :-1]))\n",
    "zscored_test = pd.DataFrame(Zscore(bias_test, test.iloc[:, :-1]))\n",
    "X = zscored_train\n",
    "Y = test.iloc[:, -1].to_numpy()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting into binary dataset\n",
    "#Takes a lot of time\n",
    "for i in range(X.shape[1]):\n",
    "    for j in range(len(X)):\n",
    "        if X.iloc[j, i] >= X.iloc[:, i].mean():\n",
    "            X.iloc[j, i] = 1\n",
    "        else:\n",
    "            X.iloc[j, i] = 0\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find target entropy\n",
    "target_zeroes, target_ones = X[X.shape[1] - 1].value_counts()\n",
    "target_entropy = -(target_zeroes / X.shape[0]) * math.log(target_zeroes / X.shape[0], 2) -\\\n",
    "(target_ones / X.shape[0]) * math.log(target_ones / X.shape[0], 2) \n",
    "target_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy(X):\n",
    "    '''\n",
    "    Returns entropies of each column in form of a dictionary, from a dataset X\n",
    "    '''\n",
    "    #First column, used this for testing as well\n",
    "    #Weirdly doing this manually produces agreeable entropy, whereas in the loop in next cell this gives negative values\n",
    "    #Might be because there's only one element in tmp0[0]\n",
    "    tmp1 = X[X[0] == 1]\n",
    "    tmp0 = X[X[0] == 0]\n",
    "    zero1, one1 = tmp1[tmp1.shape[1] - 1].value_counts()\n",
    "    E1 = -(zero1 / tmp1.shape[0] * math.log(zero1 / tmp1.shape[0], 2)) -\\\n",
    "            (one1 / tmp1.shape[0] * math.log(one1 / tmp1.shape[0], 2))\n",
    "    entropy = {0: E1 * (tmp1.shape[0]/X.shape[0])}\n",
    "    \n",
    "    for i in range(1, X.shape[1]):\n",
    "        tmp0 = X[X[i] == 0]\n",
    "        tmp1 = X[X[i] == 1]\n",
    "        #For value == 0\n",
    "        try:\n",
    "            zero0, one0 = tmp0[tmp0.shape[1] - 1].value_counts()\n",
    "        except ValueError:\n",
    "            pass\n",
    "        try:\n",
    "            E0 = -(zero0 / tmp0.shape[0] * math.log(zero0 / tmp0.shape[0], 2)) -\\\n",
    "            (one0 / tmp0.shape[0] * math.log(one0 / tmp0.shape[0], 2))\n",
    "        except NameError:\n",
    "            E0 = 0#If there's only one element, it gives me these errors\n",
    "        #For value == 1\n",
    "        try:\n",
    "            zero1, one1 = tmp1[tmp1.shape[1] - 1].value_counts()\n",
    "        except ValueError:\n",
    "            pass\n",
    "        try:\n",
    "            E1 = -(zero1 / tmp1.shape[0] * math.log(zero1 / tmp1.shape[0], 2)) -\\\n",
    "            (one1 / tmp1.shape[0] * math.log(one1 / tmp1.shape[0], 2))\n",
    "        except NameError:\n",
    "            E1 = 0\n",
    "\n",
    "        entropy[i] = E0 * (tmp0.shape[0]/X.shape[0]) + E1 * (tmp1.shape[0]/X.shape[0])\n",
    "    #entropy#Testing\n",
    "    info_gain = {}\n",
    "    for k in entropy:\n",
    "        info_gain[k] = target_entropy - entropy[k]\n",
    "    \n",
    "    return info_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class tree:\n",
    "    def __init__(self, col, x):\n",
    "        self.col = col\n",
    "        self.x = x\n",
    "    def check(self, data):\n",
    "        x = data[self.col]\n",
    "        return x == self.x\n",
    "    #Incomplete\n",
    "\n",
    "def get_max_entropy(X):\n",
    "    gain = get_entropy(X)\n",
    "    max = 0\n",
    "    for i in gain:\n",
    "        if max < gain[i]:\n",
    "            max = gain[i]\n",
    "    return max, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_entropy, col = get_max_entropy(X)#For dominant feature\n",
    "max_entropy, col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things left to do : Creating tree using the class tree and predicting values. But already past the dealine so I'll take reduction in marks and keep working on this(for myself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = {col:max_entropy}#Starting point\n",
    "Xnew = X\n",
    "\n",
    "for i in range(X.shape[1]):\n",
    "    try:\n",
    "        Xnew = Xnew.drop(columns = col)\n",
    "        max_new, col_new = get_max_entropy(Xnew)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    di[col_new] = max_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
